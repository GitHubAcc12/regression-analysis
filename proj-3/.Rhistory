U <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta, scale=sigma)
L[k] <- mean(x)-qnorm(1-alpha/2)*sd(x)/sqrt(n)
U[k] <- mean(x)+qnorm(1-alpha/2)*sd(x)/sqrt(n)
}
#out <- matrix(0, nrow=2, ncol=M)
#out[1,] <- L
#out[2,] <- U
return(rbind(L, U))
}
out <- ci.samples(alpha = .05, n = 5, M = 10000, theta = 0, sigma = 1)
L <- out[1,]
hist(L)
knitr::opts_chunk$set(echo = TRUE)
library(matrixcalc)
ehrenfest <- function(n, x0, m) {
# Ehrenfest urn model Markov chain
ua <- c(rep(T, x0), rep(F, m-x0))
x <- c()
for(i in 1:n) {
j <- sample(1:m, 1, replace=T)
ua[j] <- !ua[j]
x[i] <- sum(ua)
}
return(x)
}
lim <- 50
x <- ehrenfest(lim, x0=3, m=5)
plot(1:lim, x, type="b")
'%^%' <- matrix.power
P <- matrix(c(0, 1/3, 0, 0, 1, 0, 2/3, 0, 0, 2/3, 0, 1, 0, 0, 1/3, 0), nrow=4)
P%^%3
pi.0 <- matrix(c(0, 1, 0, 0), nrow=4)
t(pi.0)%*%(P%^%10)
P <- matrix(c(.2, 0, 0, .6, .7, .3, .1, 0, .1, .2, .1, .2, 0, .5, .8, .2), nrow=4)
# Converging?
P%^%10
P%^%100
P%^%1000
# solve(I-t(P)+E,e)
ar <- function(n, x0, theta) {
x <- x0
for(t in 2:n) {
x[t] <- theta*x[t-1]+rnorm(1, mean=0, sd=.1)
}
return(x)
}
x <- ar(100, 0, theta=1)
# theta=1: random walk
plot(1:100, x, type="l")
gibbs <- function(x0, n) {
x <- matrix(0, nrow=2, ncol=n)
x[,1] <- x0
for(t in 2:n) {
x[1,t] <- rnorm(1, mean=0, sd=1/sqrt(2*x[2, t-1]))
x[2,t] <- rexp(1, rate=x[1,t]^2+1)
}
return(x)
}
x0 <- c(0,1)
x <- gibbs(x0, 100)
hist(x[1,])
hist(x[2,])
plot(1:100, x[1,])
plot(1:100, x[2,])
h <- function(x){1/(x[1]^2+x[2]+1)}
y <- c()
for(t in 1:100) {
y[t] <- h(x[,t])
}
mean(y)
acf(y) # Auto Correlation Function -> Spikes=High Correlation
z <- ar(100, 0, .8)
acf(z)
# Thinning
z2 <- z[seq(1,100,by=2)]
plot(1:50,z2,type="l")
acf(z2)
z3 <- z[seq(1,100,by=3)]
acf(z3)
x <- gibbs(x0, n=10000)
x1 <- x[,-(1:50)]
y=c()
for(t in 1:10000) {
y[t] <- h(x[,t])
}
y1 <- y[-(1:50)] # Burn-in
acf(y1)
hist(y1)
y2 <- y1[seq(1,length(y1), by=2)]
acf(y2)
y3 <- y1[seq(1,length(y1), by=3)]
acf(y3)
y4 <- y1[seq(1,length(y1), by=4)]
acf(y4)
y6 <- y1[seq(1,length(y1), by=6)]
acf(y6)
monte.carlo.std.error <- sd(y6)/sqrt(length(y6))
mse.mean <- function(n, theta, M) {
g <- c()
h <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta)
h[k] <- mean(x)
g[k] <- (h[k]-theta)^2
}
mse <- mean(g)
MC.standard.error <- sd(g)/sqrt(M)
return(list(mse=mse, MCse=MC.standard.error))
}
theta <- 0
n <- 3
M <- 10000
result <- mse.mean(n, theta, M)
ci.samples <- function(alpha, n, M, theta, sigma) {
L <- c()
U <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta, scale=sigma)
L[k] <- mean(x)-qnorm(1-alpha/2)*sd(x)/sqrt(n)
U[k] <- mean(x)+qnorm(1-alpha/2)*sd(x)/sqrt(n)
}
#out <- matrix(0, nrow=2, ncol=M)
#out[1,] <- L
#out[2,] <- U
return(rbind(L, U))
}
out <- ci.samples(alpha = .05, n = 5, M = 10000, theta = 0, sigma = 1)
L <- out[1,]
U <- out[2,]
hist(L)
hist(U)
knitr::opts_chunk$set(echo = TRUE)
library(matrixcalc)
ehrenfest <- function(n, x0, m) {
# Ehrenfest urn model Markov chain
ua <- c(rep(T, x0), rep(F, m-x0))
x <- c()
for(i in 1:n) {
j <- sample(1:m, 1, replace=T)
ua[j] <- !ua[j]
x[i] <- sum(ua)
}
return(x)
}
lim <- 50
x <- ehrenfest(lim, x0=3, m=5)
plot(1:lim, x, type="b")
'%^%' <- matrix.power
P <- matrix(c(0, 1/3, 0, 0, 1, 0, 2/3, 0, 0, 2/3, 0, 1, 0, 0, 1/3, 0), nrow=4)
P%^%3
pi.0 <- matrix(c(0, 1, 0, 0), nrow=4)
t(pi.0)%*%(P%^%10)
P <- matrix(c(.2, 0, 0, .6, .7, .3, .1, 0, .1, .2, .1, .2, 0, .5, .8, .2), nrow=4)
# Converging?
P%^%10
P%^%100
P%^%1000
# solve(I-t(P)+E,e)
ar <- function(n, x0, theta) {
x <- x0
for(t in 2:n) {
x[t] <- theta*x[t-1]+rnorm(1, mean=0, sd=.1)
}
return(x)
}
x <- ar(100, 0, theta=1)
# theta=1: random walk
plot(1:100, x, type="l")
gibbs <- function(x0, n) {
x <- matrix(0, nrow=2, ncol=n)
x[,1] <- x0
for(t in 2:n) {
x[1,t] <- rnorm(1, mean=0, sd=1/sqrt(2*x[2, t-1]))
x[2,t] <- rexp(1, rate=x[1,t]^2+1)
}
return(x)
}
x0 <- c(0,1)
x <- gibbs(x0, 100)
hist(x[1,])
hist(x[2,])
plot(1:100, x[1,])
plot(1:100, x[2,])
h <- function(x){1/(x[1]^2+x[2]+1)}
y <- c()
for(t in 1:100) {
y[t] <- h(x[,t])
}
mean(y)
acf(y) # Auto Correlation Function -> Spikes=High Correlation
z <- ar(100, 0, .8)
acf(z)
# Thinning
z2 <- z[seq(1,100,by=2)]
plot(1:50,z2,type="l")
acf(z2)
z3 <- z[seq(1,100,by=3)]
acf(z3)
x <- gibbs(x0, n=10000)
x1 <- x[,-(1:50)]
y=c()
for(t in 1:10000) {
y[t] <- h(x[,t])
}
y1 <- y[-(1:50)] # Burn-in
acf(y1)
hist(y1)
y2 <- y1[seq(1,length(y1), by=2)]
acf(y2)
y3 <- y1[seq(1,length(y1), by=3)]
acf(y3)
y4 <- y1[seq(1,length(y1), by=4)]
acf(y4)
y6 <- y1[seq(1,length(y1), by=6)]
acf(y6)
monte.carlo.std.error <- sd(y6)/sqrt(length(y6))
mse.mean <- function(n, theta, M) {
g <- c()
h <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta)
h[k] <- mean(x)
g[k] <- (h[k]-theta)^2
}
mse <- mean(g)
MC.standard.error <- sd(g)/sqrt(M)
return(list(mse=mse, MCse=MC.standard.error))
}
theta <- 0
n <- 3
M <- 10000
result <- mse.mean(n, theta, M)
ci.samples <- function(alpha, n, M, theta, sigma) {
L <- c()
U <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta, scale=sigma)
L[k] <- mean(x)-qnorm(1-alpha/2)*sd(x)/sqrt(n)
U[k] <- mean(x)+qnorm(1-alpha/2)*sd(x)/sqrt(n)
}
#out <- matrix(0, nrow=2, ncol=M)
#out[1,] <- L
#out[2,] <- U
return(rbind(L, U))
}
theta <- 0
out <- ci.samples(alpha = .05, n = 5, M = 10000, theta = theta, sigma = 1)
L <- out[1,]
U <- out[2,]
hist(L)
hist(U)
I <- (L<=theta)&(U>=theta)
knitr::opts_chunk$set(echo = TRUE)
library(matrixcalc)
ehrenfest <- function(n, x0, m) {
# Ehrenfest urn model Markov chain
ua <- c(rep(T, x0), rep(F, m-x0))
x <- c()
for(i in 1:n) {
j <- sample(1:m, 1, replace=T)
ua[j] <- !ua[j]
x[i] <- sum(ua)
}
return(x)
}
lim <- 50
x <- ehrenfest(lim, x0=3, m=5)
plot(1:lim, x, type="b")
'%^%' <- matrix.power
P <- matrix(c(0, 1/3, 0, 0, 1, 0, 2/3, 0, 0, 2/3, 0, 1, 0, 0, 1/3, 0), nrow=4)
P%^%3
pi.0 <- matrix(c(0, 1, 0, 0), nrow=4)
t(pi.0)%*%(P%^%10)
P <- matrix(c(.2, 0, 0, .6, .7, .3, .1, 0, .1, .2, .1, .2, 0, .5, .8, .2), nrow=4)
# Converging?
P%^%10
P%^%100
P%^%1000
# solve(I-t(P)+E,e)
ar <- function(n, x0, theta) {
x <- x0
for(t in 2:n) {
x[t] <- theta*x[t-1]+rnorm(1, mean=0, sd=.1)
}
return(x)
}
x <- ar(100, 0, theta=1)
# theta=1: random walk
plot(1:100, x, type="l")
gibbs <- function(x0, n) {
x <- matrix(0, nrow=2, ncol=n)
x[,1] <- x0
for(t in 2:n) {
x[1,t] <- rnorm(1, mean=0, sd=1/sqrt(2*x[2, t-1]))
x[2,t] <- rexp(1, rate=x[1,t]^2+1)
}
return(x)
}
x0 <- c(0,1)
x <- gibbs(x0, 100)
hist(x[1,])
hist(x[2,])
plot(1:100, x[1,])
plot(1:100, x[2,])
h <- function(x){1/(x[1]^2+x[2]+1)}
y <- c()
for(t in 1:100) {
y[t] <- h(x[,t])
}
mean(y)
acf(y) # Auto Correlation Function -> Spikes=High Correlation
z <- ar(100, 0, .8)
acf(z)
# Thinning
z2 <- z[seq(1,100,by=2)]
plot(1:50,z2,type="l")
acf(z2)
z3 <- z[seq(1,100,by=3)]
acf(z3)
x <- gibbs(x0, n=10000)
x1 <- x[,-(1:50)]
y=c()
for(t in 1:10000) {
y[t] <- h(x[,t])
}
y1 <- y[-(1:50)] # Burn-in
acf(y1)
hist(y1)
y2 <- y1[seq(1,length(y1), by=2)]
acf(y2)
y3 <- y1[seq(1,length(y1), by=3)]
acf(y3)
y4 <- y1[seq(1,length(y1), by=4)]
acf(y4)
y6 <- y1[seq(1,length(y1), by=6)]
acf(y6)
monte.carlo.std.error <- sd(y6)/sqrt(length(y6))
mse.mean <- function(n, theta, M) {
g <- c()
h <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta)
h[k] <- mean(x)
g[k] <- (h[k]-theta)^2
}
mse <- mean(g)
MC.standard.error <- sd(g)/sqrt(M)
return(list(mse=mse, MCse=MC.standard.error))
}
theta <- 0
n <- 3
M <- 10000
result <- mse.mean(n, theta, M)
ci.samples <- function(alpha, n, M, theta, sigma) {
L <- c()
U <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta, scale=sigma)
L[k] <- mean(x)-qnorm(1-alpha/2)*sd(x)/sqrt(n)
U[k] <- mean(x)+qnorm(1-alpha/2)*sd(x)/sqrt(n)
}
#out <- matrix(0, nrow=2, ncol=M)
#out[1,] <- L
#out[2,] <- U
return(rbind(L, U))
}
theta <- 0
out <- ci.samples(alpha = .05, n = 5, M = 10000, theta = theta, sigma = 1)
L <- out[1,]
U <- out[2,]
hist(L)
hist(U)
I <- (L<=theta)&(U>=theta)
mean(I)
sd(I)/sqrt(M)
knitr::opts_chunk$set(echo = TRUE)
library(matrixcalc)
ehrenfest <- function(n, x0, m) {
# Ehrenfest urn model Markov chain
ua <- c(rep(T, x0), rep(F, m-x0))
x <- c()
for(i in 1:n) {
j <- sample(1:m, 1, replace=T)
ua[j] <- !ua[j]
x[i] <- sum(ua)
}
return(x)
}
lim <- 50
x <- ehrenfest(lim, x0=3, m=5)
plot(1:lim, x, type="b")
'%^%' <- matrix.power
P <- matrix(c(0, 1/3, 0, 0, 1, 0, 2/3, 0, 0, 2/3, 0, 1, 0, 0, 1/3, 0), nrow=4)
P%^%3
pi.0 <- matrix(c(0, 1, 0, 0), nrow=4)
t(pi.0)%*%(P%^%10)
P <- matrix(c(.2, 0, 0, .6, .7, .3, .1, 0, .1, .2, .1, .2, 0, .5, .8, .2), nrow=4)
# Converging?
P%^%10
P%^%100
P%^%1000
# solve(I-t(P)+E,e)
ar <- function(n, x0, theta) {
x <- x0
for(t in 2:n) {
x[t] <- theta*x[t-1]+rnorm(1, mean=0, sd=.1)
}
return(x)
}
x <- ar(100, 0, theta=1)
# theta=1: random walk
plot(1:100, x, type="l")
gibbs <- function(x0, n) {
x <- matrix(0, nrow=2, ncol=n)
x[,1] <- x0
for(t in 2:n) {
x[1,t] <- rnorm(1, mean=0, sd=1/sqrt(2*x[2, t-1]))
x[2,t] <- rexp(1, rate=x[1,t]^2+1)
}
return(x)
}
x0 <- c(0,1)
x <- gibbs(x0, 100)
hist(x[1,])
hist(x[2,])
plot(1:100, x[1,])
plot(1:100, x[2,])
h <- function(x){1/(x[1]^2+x[2]+1)}
y <- c()
for(t in 1:100) {
y[t] <- h(x[,t])
}
mean(y)
acf(y) # Auto Correlation Function -> Spikes=High Correlation
z <- ar(100, 0, .8)
acf(z)
# Thinning
z2 <- z[seq(1,100,by=2)]
plot(1:50,z2,type="l")
acf(z2)
z3 <- z[seq(1,100,by=3)]
acf(z3)
x <- gibbs(x0, n=10000)
x1 <- x[,-(1:50)]
y=c()
for(t in 1:10000) {
y[t] <- h(x[,t])
}
y1 <- y[-(1:50)] # Burn-in
acf(y1)
hist(y1)
y2 <- y1[seq(1,length(y1), by=2)]
acf(y2)
y3 <- y1[seq(1,length(y1), by=3)]
acf(y3)
y4 <- y1[seq(1,length(y1), by=4)]
acf(y4)
y6 <- y1[seq(1,length(y1), by=6)]
acf(y6)
monte.carlo.std.error <- sd(y6)/sqrt(length(y6))
mse.mean <- function(n, theta, M) {
g <- c()
h <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta)
h[k] <- mean(x)
g[k] <- (h[k]-theta)^2
}
mse <- mean(g)
MC.standard.error <- sd(g)/sqrt(M)
return(list(mse=mse, MCse=MC.standard.error))
}
theta <- 0
n <- 3
M <- 10000
result <- mse.mean(n, theta, M)
ci.samples <- function(alpha, n, M, theta, sigma) {
L <- c()
U <- c()
for(k in 1:M) {
x <- rlogis(n, location=theta, scale=sigma)
L[k] <- mean(x)-qnorm(1-alpha/2)*sd(x)/sqrt(n)
U[k] <- mean(x)+qnorm(1-alpha/2)*sd(x)/sqrt(n)
}
#out <- matrix(0, nrow=2, ncol=M)
#out[1,] <- L
#out[2,] <- U
return(rbind(L, U))
}
theta <- 0
M <- 10000
out <- ci.samples(alpha = .05, n = 5, M = M, theta = theta, sigma = 1)
L <- out[1,]
U <- out[2,]
hist(L)
hist(U)
I <- (L<=theta)&(U>=theta)
mean(I)
sd(I)/sqrt(M)
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex2.R', echo=TRUE)
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex2.R', echo=TRUE)
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex2.R', echo=TRUE)
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex2.R', echo=TRUE)
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex2.R', echo=TRUE)
n
p
n-p
inf.thresh
inf.points
source('~/Documents/Master/Milwaukee/Semester 1/Regression Analysis/Homework/HW6/ex4.R', echo=TRUE)
